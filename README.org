* Project in biostatistics: hyperparameter optimization

** Background and motivation

We consider two different problems of applied biostatistics:

1. the making of a medical risk prediction model
2. semi-parametric estimation of a real valued target parameter in the presence of a high dimensional nuissance parameter

Both problems can be approached using methods from machine learning
and hence they share the important task of hyperparameter
optimization, aka tuning. Interestingly, the optimal value of the
hyperparameter of a machine learning method is typically not the same
for the two problems. This phenomenom is illustrated by the R-code
below in the case of a penalized linear ridge regression with tuning
parameter lambda. Compared are the optimal lambda values for
1. predicting the outcome Y and 2. the average treatment effect of a
binary variable A.

*** Example: Tuning a penalized linear regression

#+BEGIN_SRC R  :results output raw drawer  :exports code  :session *R* :cache yes  
library(glmnet)
library(data.table)
library(ggplot2)
library(riskRegression)
library(lava)
library(foreach)

simulator <- function(n=1000, p=10, effect.size){
  X = paste0("X",1:10)
  m =  lvm()
  distribution(m,X) = normal.lvm()
  distribution(m,"A") = binomial.lvm()
  distribution(m,"Y") = normal.lvm()
  regression(m) = as.formula(paste0("Y ~ f(A,",effect.size,")"))
  return(sim(m,n))
}
glm(Y~A,data = simulator(effect.size = .8))

runner <- function(M, lambda=round(exp(seq(2.5, -4, length.out=200)),4), alpha=0, ...){
  out <- foreach(m = 1:M,.combine = "rbind") %do%{
    train <- simulator(n = 1000, effect.size = .2)
    model <- glmnet(train[, -match("Y",names(train))], train[,"Y"], alpha=alpha, lambda=lambda,...)
    test <- simulator(n=10000,effect.size = .2)
    predicted.values <- predict(model, newx=as.matrix(test[, -match("Y",names(test))]))
    ## Mean squared prediction error
    ## +++++++++++++++++++++++++++++
    prediction.error <- data.table(lambda=lambda,
                                   mse=apply((predicted.values - test[["Y"]])^2, 2, mean),
                                   target="prediction",
                                   sim=m)
    ## Mean squared error of G-formula estimate of target parameter
    ## ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
    dat.copy <- copy(train)
    dat.copy[["A"]] = 0
    fit0 <- predict(model, newx=as.matrix(dat.copy[, -1]))
    dat.copy[["A"]] = 1
    fit1 <- predict(model, newx=as.matrix(dat.copy[, -1]))
    mse.target <- data.table(lambda=lambda,mse=(apply(fit1-fit0, 2, mean)-effect.size)^2,target="ATE",sim=m)
    return(rbind(prediction.error, mse.target))
  }
  Out = out[,.(MSE =mean(mse)),by = c("lambda","target")]
  return(Out[])
}
set.seed(341)
x <- runner(M=20)

x[, std.MSE := (MSE-min(MSE))/(max(MSE)-min(MSE)), by = .(target)]
ggplot(x, aes(x=log(lambda), y=std.MSE, col=target)) + theme_bw() +
  geom_line() + ylab("Standardized MSE") + 
  geom_point(data=x[std.MSE==0], size=2) 
#+END_SRC

** Real world data

You will work with a random subset of the data described in Wikkelsø
et al. 2014 (Reference [1] below). The dataset contains data from
48272 Danish women who gave birth twice. The main outcome is a binary
variable called =PPHbin= which indicates if the woman had a postpartum
haemorrhage (heavy bleeding) during the second delivery.

1. You develop a model that predicts postpartum haemorrhage at the
   second delivery based on characteristics of the first delivery.
2. You estimate the causal effect of a planned cesarian section on the
   risk of postpartum haemorrhage, i.e., the effect of a hypothetical study
   which randomizes women to either intended cesarian section or intended
   vaginal birth.

* Methodology

Here are some keywords and references. Detailed instructions regarding
the project work are provided at the group meetings.

** Prediction model

You choose a machine learning method for binary outcomes:

 - penalized regression 
 - random forest
 - superlearner 
   

** Mean squared error of prediction

You estimate the mean squared error of prediction using the Brier
score. You describe the challenges of cross-validation in theoretical
terms (formula that describes the cross-validation estimator of MSE,
what is estimated?) and practical terms (Monte-Carlo error, choice of
folds).

** Causal inference

You describe the causal effect with counterfactual variables and
discuss the assumptions that are needed in order to identify the
causal effect from the real world data from a theoretical (definition
of the assumptions) and from an applied perspective (how likely are
they satisfied).

** Semi-parametric efficiency theory

You describe the target parameter, i.e., the causal effect, as a
functional operating on the space of probability measures of the
observations \(Y,A,W\) where \(Y\) is the outcome (postpartum
haemorrhage), \(A\) the treatment (planned cesarian section) and W all
the variables from the first birth. You derive the canonical gradient
of the functional (aka the Gateaux derivative). You estimate the
nuissance parameters using the prediction model from above and a
second model which predicts the probability of a planned cesarian
section \(A=1\) based on \(W\).
 

* References

1. Anne J Wikkelsø, Sofie Hjortø, Thomas A Gerds, Ann M Møller, and
    Jens Langhoff-Roos. Prediction of postpartum blood transfusion --
    risk factors and recurrence. The Journal of Maternal-Fetal &
    Neonatal Medicine, 27(16):1661-1667, 2014.

