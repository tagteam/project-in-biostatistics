#+TITLE: Project in biostatistics: Targeted learning and cross-fitting
#+Author: Anders Munch & Thomas Alexander Gerds
#+LANGUAGE:  en
#+OPTIONS: H:3 num:t toc:nil \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS: TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc author:nil
#+LaTeX_CLASS: org-article
#+LaTeX_HEADER:\usepackage{authblk}
#+LaTeX_HEADER:\usepackage{natbib}
#+LaTeX_HEADER:\usepackage[table,usenames,dvipsnames]{xcolor}
#+LaTeX_HEADER:\definecolor{lightGray}{gray}{0.98}
#+LaTeX_HEADER:\definecolor{medioGray}{gray}{0.83}
#+LaTeX_HEADER:\newcommand{\diff}{\mathrm d}
#+LaTeX_HEADER:\newcommand{\empmeas}{P_n}
#+LaTeX_HEADER:\author{Anders Munch \& Thomas Alexander Gerds}
#+LaTeX_HEADER:\affil{Department of Biostatistics, University of Copenhagen}
#+setupfile:~/emacs-genome/snps/org-templates/setup-all-purpose.org
#+superman-export-target: pdf


** Background and motivation

The central philosophy of targeted learning is to clearly separate the
definition of the parameter of interest, /the target parameter/, and
the models/algorithms used for estimation. Let \( \mathcal{P} \) be a
collection of probability measures and \( \Psi \colon \mathcal{P}
\rightarrow R\) a pathwise differentiable parameter of interest,
called /the target parameter/.  In this project we consider estimation
problems, where the parameter \( \Psi \) can be written as
\begin{equation}\label{eq1}
  \Psi(P) = \int \phi(x, \nu(P)) P(\diff x) = P{[\phi(\cdot, \nu(P))]}.
\end{equation}
In this setting \( \nu: \mathcal P \to \mathcal F \) is a
function-valued nuisance parameter, such that \(v(P)\) is a regression
function.  Note also that we use the notation \( P{[f]} = \int f \diff
P \). By using tools from semiparametric efficiency theory it is
possible to choose the function $\phi$ such that valid statistical
inference for $\Psi$ can be obtained, even when $\nu$ is estimated
with data-adaptive algorithms and machine learning
\citep{van2011targeted,chernozhukov2018double}.

Let \( \empmeas \) denote the empirical measure of an
iid.\nbsp{}sample \( \{O_i\}_{i=1}^n \) from some \( P \in
\mathcal{P}\) and suppose we have been given an estimator
$\hat{\nu}_n$ of the nuisance parameter $\nu$. Then, a natural
estimator of the target parameter $\Psi$ is
\begin{equation*}
  \hat{\Psi}_n = \empmeas{[\phi(\cdot, \hat{\nu}_n)]}. 
\end{equation*}
This estimator will be consistent and asymptotically normal under a set of
regularity assumptions about the function \( \phi \) and the set \(\mathcal P\) if the estimator
\( \hat{\nu}_n \) converges sufficiently fast to \(\nu(P)\) for all \(P\in\mathcal P\). One assumption is that \( \hat{\nu}_n \) takes values in a
so-called \textit{Donsker class} of functions. To avoid this assumption it has
been suggested to instead employ \textit{cross-fitting}, where \( \empmeas \)
and $\hat{\nu}_n$ are constructed using separate parts of the data
\citep{chernozhukov2018double}.

* The project

In this project we aim to learn about the theoretical and practical
properties of cross-fitting in the context of targeted learning. You
will work with the data described in \citep{wikkelso2014prediction}.
The dataset available for this project contains data from 48,272
Danish women who all gave birth twice. The main outcome is a binary
variable indicating if the woman had a postpartum haemorrhage (heavy
bleeding) during the second delivery. The target parameter is the
causal effect of a planned cesarian section on the risk of postpartum
haemorrhage at the second delivery. This parameter is a special case
of equation ref:eq1 where \(\nu(P)\) is the conditional probability of
a planned cesarian section at the second delivery given
characteristics of the first delivery. Under the usual assumptions
needed for causal inference, the causal effect coincides with the one
of a hypothetical study which randomizes women to either planned
cesarian section or intended vaginal birth.

You will derive a cross-fitting algorithm and construct a targeted
minimum loss based estimator
\citep{van2006targeted,van2011targeted}. You will study the role of
cross-fitting for the asymptotic inference theoretically and the
effect of cross-fitting in finite samples. In this project we work
with elements of causal inference and asymptotic semiparametric
theory. Good introductions to the theory of targeted learning are
cite:kennedy2016semiparametric,kennedy2022semiparametric and
cite:hines2022demystifying. Relevant papers on cross-fitting are
cite:newey2018cross,chen2022debiased and cite:zivich2021machine.

bibliography:bib.bib
bibliographystyle:chicago
